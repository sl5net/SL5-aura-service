# Filename: scripts/py/func/checks/test_dictation_session_logic.py

import unittest
import unittest.mock
import wave
# import queue
import time
import logging
from pathlib import Path
import vosk
import threading

# Ensure the script can find the modules in the parent directory
import sys
sys.path.append(str(Path(__file__).resolve().parent.parent.parent))

from scripts.py.func.transcribe_audio_with_feedback import transcribe_audio_with_feedback
from config.settings import TRIGGER_FILE_PATH, SAMPLE_RATE

# --- Basic Configuration ---
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
MODEL_PATH = "models/vosk-model-small-en-us-0.15"
TEST_WAV_PATH = Path(__file__).resolve().parent / "test_audio_16k.wav"

class MockRawInputStream:
    # ... (Dieser Teil bleibt unver√§ndert) ...
    def __init__(self, samplerate, blocksize, dtype, channels, callback):
        logging.info("MockRawInputStream: Initialized.")
        self._callback = callback
        self._wav_file = wave.open(str(TEST_WAV_PATH), 'rb')
        assert self._wav_file.getframerate() == samplerate, "WAV file sample rate mismatch"
        assert self._wav_file.getnchannels() == channels, "WAV file channel mismatch"
        self._blocksize = blocksize
        self._stop_event = threading.Event()
        self._thread = threading.Thread(target=self._run_simulation)
    def _run_simulation(self):
        logging.info("MockRawInputStream: Simulation thread started.")
        while not self._stop_event.is_set():
            data = self._wav_file.readframes(self._blocksize)
            if not data:
                logging.info("MockRawInputStream: End of WAV file reached.")
                break
            self._callback(data, None, None, None)
            time.sleep(float(self._blocksize) / self._wav_file.getframerate())
        logging.info("MockRawInputStream: Simulation thread finished.")
    def __enter__(self):
        logging.info("MockRawInputStream: Starting simulation.")
        self._thread.start()
        return self
    def __exit__(self, exc_type, exc_val, exc_tb):
        logging.info("MockRawInputStream: Stopping simulation.")
        self._stop_event.set()
        self._thread.join()
        self._wav_file.close()
        logging.info("MockRawInputStream: Cleanup complete.")

class TestDictationLogic(unittest.TestCase):

    def setUp(self):
        """This method is run before each test, ensuring a clean state."""
        trigger_file = Path(TRIGGER_FILE_PATH)
        if trigger_file.exists():
            logging.warning(f"Setup: Found and removed existing trigger file at {TRIGGER_FILE_PATH}")
            trigger_file.unlink()

        # Load the model once for all tests in this class
        if not hasattr(self, 'model'):
            self.assertTrue(Path(MODEL_PATH).exists(), f"Vosk model not found at {MODEL_PATH}")
            self.model = vosk.Model(MODEL_PATH)


    @unittest.mock.patch('scripts.py.func.transcribe_audio_with_feedback.sd.RawInputStream', new=MockRawInputStream)
    def test_transcription_with_short_pause_yields_one_chunk(self):

        """
        Tests if continuous speech (with short pauses) is correctly transcribed as a single chunk.
        This test uses the current test_audio_16k.wav.
        """
        logging.info("--- Starting test: transcription with short pause yields one chunk ---")
        recognizer = vosk.KaldiRecognizer(self.model, SAMPLE_RATE)

        expected_text = "the first test sequence is now complete ready to proceed with the second phase"


        # === START OF CORRECTION ===
        # Create a dummy event that is always "active" for the test
        test_session_event = threading.Event()
        test_session_event.set()

        generator = transcribe_audio_with_feedback(logging
                   , recognizer
                   , "en-US"
                   , initial_silence_timeout=10.0
                   , session_active_event=test_session_event
                   , AUTO_ENTER_AFTER_DICTATION_global=0)
        transcribed_chunks = [chunk for chunk in generator if chunk] # Collect non-empty chunks

        logging.info(f"Final transcribed chunks: {transcribed_chunks}")

        self.assertEqual(len(transcribed_chunks), 1, "Expected exactly one chunk for short-pause audio.")
        self.assertEqual(transcribed_chunks[0], expected_text, "The transcribed content of the single chunk is incorrect.")
        logging.info("--- Test successfully completed! ---")

    @unittest.skip("Requires a new audio file with a distinct 1-2 second pause between sentences.")
    @unittest.mock.patch('scripts.py.func.transcribe_audio_with_feedback.sd.RawInputStream', new=MockRawInputStream)
    def test_transcription_with_long_pause_yields_multiple_chunks(self):
        """
        Tests if speech with long pauses is correctly transcribed into multiple chunks.
        This test is currently skipped and needs a suitable audio file to be enabled.
        """
        logging.info("--- Starting test: transcription with long pause yields multiple chunks ---")
        recognizer = vosk.KaldiRecognizer(self.model, SAMPLE_RATE)

        expected_texts = [
            "the first test sequence is now complete",
            "ready to proceed with the second phase"
        ]

        generator = transcribe_audio_with_feedback(logging, recognizer, "en-US", initial_silence_timeout=10.0, AUTO_ENTER_AFTER_DICTATION_global=0)
        transcribed_chunks = [chunk for chunk in generator if chunk]

        logging.info(f"Final transcribed chunks: {transcribed_chunks}")
        self.assertEqual(len(transcribed_chunks), len(expected_texts), "Incorrect number of chunks transcribed.")

        for i, expected in enumerate(expected_texts):
            self.assertEqual(transcribed_chunks[i], expected, f"Mismatch in chunk {i}")
        logging.info("--- Test successfully completed! ---")

if __name__ == '__main__':
    unittest.main()
